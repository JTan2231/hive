# hivemind
Distributed computing for large language models.

## Note
LLMs are fairly serial, so this is more of an accommodation for memory rather than performance.
